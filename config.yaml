# Model Configuration
model:
  num_heroes: 150
  embedding_dim: 256  # UP from 128 for capacity
  num_layers: 4
  num_heads: 8
  dropout: 0.1        # Reduced dropout

# Training Configuration
training:
  batch_size: 512     # UP for GPU Utilization
  learning_rate: 0.0003 # Adjusted for batch size
  num_epochs: 100     # Extended training run
  device: "cpu"  # or "cpu"
  early_stopping_patience: 5

# Data Configuration
data:
  num_matches: 10000
  val_split: 0.15
  test_split: 0.15
  min_draft_length: 20

# Paths
path:
  data_dir: "data"
  model_dir: "models"
  log_dir: "logs"